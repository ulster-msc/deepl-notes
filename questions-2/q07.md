![Question 7](https://github.com/ulster-msc/deepl-notes/blob/main/questions-2/Screenshot%202025-11-06%20at%2017.07.53.png?raw=true)

Question 7 — Fill in backpropagation steps

- Final answers
  - A: Compute/measure the error (loss) between the predicted and actual output.
  - B: Compute/calculate the gradients of the loss with respect to each weight.
  - C: Update the network weights using those gradients (via the optimizer).

References (lectures/practicals used)
- lectures/Lecture 2 - 2025.pdf — p.3 (learning with error/gradient)
- lectures/Lecture 4 - 2025.pdf — p.6 (backprop/chain rule computing gradients to update weights)

