![Question 14](https://github.com/ulster-msc/deepl-notes/blob/main/questions/Screenshot%202025-11-06%20at%2015.33.15.png?raw=true)

Question 14 — Complete CNN (Keras Functional API)

Design rationale and constraints satisfied
- Input: RGB images of size 128×128 → tensor shape `(128, 128, 3)` for the visible input.
- Three convolution + pooling stages act as feature extractors. We insert Batch Normalization to stabilize training and Dropout for regularization as instructed.
- After feature extraction, we flatten and use two fully connected layers with Dropout in between.
- Output: 4‑class prediction with softmax activation.

Completed code
```python
from keras.models import Model
from keras.layers import Input, Dense, Flatten, Dropout
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization

visible = Input(shape=(128, 128, 3))

conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(visible)
bn1 = BatchNormalization()(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)
drop1 = Dropout(0.25)(pool1)

conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(drop1)
bn2 = BatchNormalization()(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)
drop2 = Dropout(0.25)(pool2)

conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(drop2)
bn3 = BatchNormalization()(conv3)
pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)
drop3 = Dropout(0.5)(pool3)

flat1 = Flatten()(drop3)
hidden1 = Dense(512, activation='relu')(flat1)
drop4 = Dropout(0.5)(hidden1)
hidden2 = Dense(256, activation='relu')(drop4)

output = Dense(4, activation='softmax')(hidden2)

model = Model(inputs=visible, outputs=output)
```

References (lectures/practicals used)
- lectures/Lecture 7 - 2025.pdf — p.1–4 (CNN blocks, BatchNormalization and Dropout usage)
